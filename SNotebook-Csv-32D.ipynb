{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d07c78a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import importlib\n",
    "import Scsv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d18e6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef3c95a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: agg\n"
     ]
    }
   ],
   "source": [
    "%matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4d42a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "from operator import add\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "from pyspark.ml.feature import RegexTokenizer\n",
    "from pyspark.ml.feature import Word2Vec\n",
    "from pyspark.ml.feature import StopWordsRemover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9450ddc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MASTER= \"spark://virtual01-virtualbox:7077\"\n",
    "MASTER= \"local[*]\"\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    "    .appName(\"MyProj\")\\\n",
    "    .master(MASTER)\\\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True)\\\n",
    "    .getOrCreate()\n",
    "\n",
    "fname=\"hdfs://zuk:9000/dataset/twitter/Tweets.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df1a01ef",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = spark.read.option(\"header\",True).csv(fname)\\\n",
    "    .select(\"airline_sentiment\",\"text\")\n",
    "\n",
    "rter = RegexTokenizer(inputCol=\"text\", outputCol=\"token\", pattern=\"[\\\\W]+\", minTokenLength=3)\n",
    "tokenized = rter.transform(df.na.fill(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d19ed3da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14837"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "more_stopwords=[\"virginamerica\",\"https\",\"ual\",\"nyc\"]\n",
    "more_stopwords.extend(StopWordsRemover().getStopWords())\n",
    "\n",
    "remover = StopWordsRemover(inputCol=\"token\", outputCol=\"rtoken\").setStopWords(more_stopwords)\n",
    "removed = remover.transform(tokenized)\n",
    "\n",
    "removed.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c661f91e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>airline_sentiment</th><th>rtoken</th></tr>\n",
       "<tr><td>neutral</td><td>[dhepburn, said]</td></tr>\n",
       "<tr><td>positive</td><td>[plus, added, com...</td></tr>\n",
       "<tr><td>neutral</td><td>[didn, today, mus...</td></tr>\n",
       "<tr><td>negative</td><td>[really, aggressi...</td></tr>\n",
       "<tr><td>negative</td><td>[really, big, bad...</td></tr>\n",
       "<tr><td>negative</td><td>[seriously, pay, ...</td></tr>\n",
       "<tr><td> </td><td>[]</td></tr>\n",
       "<tr><td>positive</td><td>[yes, nearly, eve...</td></tr>\n",
       "<tr><td>neutral</td><td>[really, missed, ...</td></tr>\n",
       "<tr><td>positive</td><td>[well, didn]</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-----------------+--------------------+\n",
       "|airline_sentiment|              rtoken|\n",
       "+-----------------+--------------------+\n",
       "|          neutral|    [dhepburn, said]|\n",
       "|         positive|[plus, added, com...|\n",
       "|          neutral|[didn, today, mus...|\n",
       "|         negative|[really, aggressi...|\n",
       "|         negative|[really, big, bad...|\n",
       "|         negative|[seriously, pay, ...|\n",
       "|                 |                  []|\n",
       "|         positive|[yes, nearly, eve...|\n",
       "|          neutral|[really, missed, ...|\n",
       "|         positive|        [well, didn]|\n",
       "+-----------------+--------------------+"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "removed.select(\"airline_sentiment\",\"rtoken\").limit(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9aa7dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "oname = fname.replace(\"/\", \"\").replace(\":\", \"\")\n",
    "# !transform data\n",
    "\n",
    "word2Vec = Word2Vec(vectorSize=32, minCount=1,\n",
    "                    inputCol=\"rtoken\", outputCol=\"vector\")\n",
    "\n",
    "model = word2Vec.fit(removed)\n",
    "\n",
    "\n",
    "result = model.transform(removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "463497a0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "samples = 100\n",
    "\n",
    "wds1 = result.select(\"rtoken\")\\\n",
    "    .filter(\"airline_sentiment = \\\"positive\\\" OR airline_sentiment = \\\"neutral\\\"\")\\\n",
    "    .head(samples)\n",
    "vecs1 = result.select(\"vector\")\\\n",
    "    .filter(\"airline_sentiment = \\\"positive\\\" OR airline_sentiment = \\\"neutral\\\"\")\\\n",
    "    .head(samples)\n",
    "\n",
    "wds2 = result.select(\"rtoken\")\\\n",
    "    .filter(result.airline_sentiment ==\"negative\")\\\n",
    "    .head(samples)\n",
    "vecs2 = result.select(\"vector\")\\\n",
    "    .filter(result.airline_sentiment ==\"negative\")\\\n",
    "    .head(samples)\n",
    "\n",
    "cnt1 = len(vecs1)\n",
    "cnt2 = len(vecs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a70b50d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(rtoken=['dhepburn', 'said']),\n",
       " Row(rtoken=['plus', 'added', 'commercials', 'experience', 'tacky']),\n",
       " Row(rtoken=['didn', 'today', 'must', 'mean', 'need', 'take', 'another', 'trip']),\n",
       " Row(rtoken=['yes', 'nearly', 'every', 'time', 'fly', 'ear', 'worm', 'won', 'away']),\n",
       " Row(rtoken=['really', 'missed', 'prime', 'opportunity', 'men', 'without', 'hats', 'parody', 'mwpg7grezp'])]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Row(rtoken=['really', 'aggressive', 'blast', 'obnoxious', 'entertainment', 'guests', 'faces', 'amp', 'little', 'recourse']),\n",
       " Row(rtoken=['really', 'big', 'bad', 'thing']),\n",
       " Row(rtoken=['seriously', 'pay', 'flight', 'seats', 'didn', 'playing']),\n",
       " Row(rtoken=['sfo', 'pdx', 'schedule', 'still', 'mia']),\n",
       " Row(rtoken=['flew', 'sfo', 'last', 'week', 'couldn', 'fully', 'sit', 'seat', 'due', 'two', 'large', 'gentleman', 'either', 'side', 'help'])]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(wds1[0:5])\n",
    "display(wds2[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed4ac50f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>word</th><th>similarity</th></tr>\n",
       "<tr><td>southwestverity</td><td>0.8988014459609985</td></tr>\n",
       "<tr><td>papers</td><td>0.8939696550369263</td></tr>\n",
       "<tr><td>sammi_jon3s</td><td>0.8735257983207703</td></tr>\n",
       "<tr><td>released</td><td>0.8612871766090393</td></tr>\n",
       "<tr><td>100</td><td>0.860431432723999</td></tr>\n",
       "<tr><td>premier</td><td>0.8581547141075134</td></tr>\n",
       "<tr><td>degree</td><td>0.8556652069091797</td></tr>\n",
       "<tr><td>utah</td><td>0.8522842526435852</td></tr>\n",
       "<tr><td>mention</td><td>0.8516773581504822</td></tr>\n",
       "<tr><td>husband</td><td>0.8511340022087097</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+---------------+------------------+\n",
       "|           word|        similarity|\n",
       "+---------------+------------------+\n",
       "|southwestverity|0.8988014459609985|\n",
       "|         papers|0.8939696550369263|\n",
       "|    sammi_jon3s|0.8735257983207703|\n",
       "|       released|0.8612871766090393|\n",
       "|            100| 0.860431432723999|\n",
       "|        premier|0.8581547141075134|\n",
       "|         degree|0.8556652069091797|\n",
       "|           utah|0.8522842526435852|\n",
       "|        mention|0.8516773581504822|\n",
       "|        husband|0.8511340022087097|\n",
       "+---------------+------------------+"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.findSynonyms(\"rain\",10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2bb5b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- airline_sentiment: string (nullable = false)\n",
      " |-- text: string (nullable = false)\n",
      " |-- token: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- rtoken: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- vector: vector (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14837"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.printSchema()\n",
    "result.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40751d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+\n",
      "|airline_sentiment|count|\n",
      "+-----------------+-----+\n",
      "|         negative| 9178|\n",
      "|          neutral| 3099|\n",
      "|         positive| 2363|\n",
      "+-----------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "df1 = df.filter(\"airline_sentiment = \\\"positive\\\" OR airline_sentiment = \\\"neutral\\\" OR airline_sentiment = \\\"negative\\\"\")\n",
    "# unknown sentiment values are removed\n",
    "\n",
    "df1.groupBy(\"airline_sentiment\")\\\n",
    "    .count()\\\n",
    "    .orderBy(col(\"count\").desc())\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e437249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>airline_sentiment</th><th>text</th><th>token</th><th>rtoken</th><th>vector</th><th>label</th></tr>\n",
       "<tr><td>neutral</td><td>@VirginAmerica Wh...</td><td>[virginamerica, w...</td><td>[dhepburn, said]</td><td>[0.04504764056764...</td><td>1.0</td></tr>\n",
       "<tr><td>positive</td><td>@VirginAmerica pl...</td><td>[virginamerica, p...</td><td>[plus, added, com...</td><td>[0.04508242197334...</td><td>2.0</td></tr>\n",
       "<tr><td>neutral</td><td>@VirginAmerica I ...</td><td>[virginamerica, d...</td><td>[didn, today, mus...</td><td>[-0.0058883361052...</td><td>1.0</td></tr>\n",
       "<tr><td>negative</td><td>&quot;@VirginAmerica i...</td><td>[virginamerica, r...</td><td>[really, aggressi...</td><td>[0.01358438511379...</td><td>0.0</td></tr>\n",
       "<tr><td>negative</td><td>@VirginAmerica an...</td><td>[virginamerica, a...</td><td>[really, big, bad...</td><td>[0.07137722894549...</td><td>0.0</td></tr>\n",
       "<tr><td>negative</td><td>@VirginAmerica se...</td><td>[virginamerica, s...</td><td>[seriously, pay, ...</td><td>[-0.0400419132784...</td><td>0.0</td></tr>\n",
       "<tr><td>positive</td><td>@VirginAmerica ye...</td><td>[virginamerica, y...</td><td>[yes, nearly, eve...</td><td>[0.03987884793120...</td><td>2.0</td></tr>\n",
       "<tr><td>neutral</td><td>@VirginAmerica Re...</td><td>[virginamerica, r...</td><td>[really, missed, ...</td><td>[0.00365064489758...</td><td>1.0</td></tr>\n",
       "<tr><td>positive</td><td>@virginamerica We...</td><td>[virginamerica, w...</td><td>[well, didn]</td><td>[0.03906816244125...</td><td>2.0</td></tr>\n",
       "<tr><td>positive</td><td>@VirginAmerica it...</td><td>[virginamerica, w...</td><td>[amazing, arrived...</td><td>[0.09566467329859...</td><td>2.0</td></tr>\n",
       "<tr><td>neutral</td><td>@VirginAmerica di...</td><td>[virginamerica, d...</td><td>[know, suicide, s...</td><td>[0.03508416935801...</td><td>1.0</td></tr>\n",
       "<tr><td>positive</td><td>@VirginAmerica I ...</td><td>[virginamerica, p...</td><td>[pretty, graphics...</td><td>[0.02499789802823...</td><td>2.0</td></tr>\n",
       "<tr><td>positive</td><td>@VirginAmerica Th...</td><td>[virginamerica, t...</td><td>[great, deal, alr...</td><td>[0.02826612898414...</td><td>2.0</td></tr>\n",
       "<tr><td>positive</td><td>@VirginAmerica @v...</td><td>[virginamerica, v...</td><td>[virginmedia, fly...</td><td>[-0.0038239073103...</td><td>2.0</td></tr>\n",
       "<tr><td>positive</td><td>@VirginAmerica Th...</td><td>[virginamerica, t...</td><td>[thanks]</td><td>[-0.1997427940368...</td><td>2.0</td></tr>\n",
       "<tr><td>negative</td><td>@VirginAmerica SF...</td><td>[virginamerica, s...</td><td>[sfo, pdx, schedu...</td><td>[0.02190662324428...</td><td>0.0</td></tr>\n",
       "<tr><td>positive</td><td>@VirginAmerica So...</td><td>[virginamerica, e...</td><td>[excited, first, ...</td><td>[-0.0296566172536...</td><td>2.0</td></tr>\n",
       "<tr><td>negative</td><td>@VirginAmerica  I...</td><td>[virginamerica, f...</td><td>[flew, sfo, last,...</td><td>[0.02892880649305...</td><td>0.0</td></tr>\n",
       "<tr><td>positive</td><td>I ❤️ flying @Virg...</td><td>[flying, virginam...</td><td>[flying]</td><td>[-0.0573806241154...</td><td>2.0</td></tr>\n",
       "<tr><td>positive</td><td>@VirginAmerica yo...</td><td>[virginamerica, y...</td><td>[know, amazingly,...</td><td>[-0.0202496654819...</td><td>2.0</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "+-----------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
       "|airline_sentiment|                text|               token|              rtoken|              vector|label|\n",
       "+-----------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
       "|          neutral|@VirginAmerica Wh...|[virginamerica, w...|    [dhepburn, said]|[0.04504764056764...|  1.0|\n",
       "|         positive|@VirginAmerica pl...|[virginamerica, p...|[plus, added, com...|[0.04508242197334...|  2.0|\n",
       "|          neutral|@VirginAmerica I ...|[virginamerica, d...|[didn, today, mus...|[-0.0058883361052...|  1.0|\n",
       "|         negative|\"@VirginAmerica i...|[virginamerica, r...|[really, aggressi...|[0.01358438511379...|  0.0|\n",
       "|         negative|@VirginAmerica an...|[virginamerica, a...|[really, big, bad...|[0.07137722894549...|  0.0|\n",
       "|         negative|@VirginAmerica se...|[virginamerica, s...|[seriously, pay, ...|[-0.0400419132784...|  0.0|\n",
       "|         positive|@VirginAmerica ye...|[virginamerica, y...|[yes, nearly, eve...|[0.03987884793120...|  2.0|\n",
       "|          neutral|@VirginAmerica Re...|[virginamerica, r...|[really, missed, ...|[0.00365064489758...|  1.0|\n",
       "|         positive|@virginamerica We...|[virginamerica, w...|        [well, didn]|[0.03906816244125...|  2.0|\n",
       "|         positive|@VirginAmerica it...|[virginamerica, w...|[amazing, arrived...|[0.09566467329859...|  2.0|\n",
       "|          neutral|@VirginAmerica di...|[virginamerica, d...|[know, suicide, s...|[0.03508416935801...|  1.0|\n",
       "|         positive|@VirginAmerica I ...|[virginamerica, p...|[pretty, graphics...|[0.02499789802823...|  2.0|\n",
       "|         positive|@VirginAmerica Th...|[virginamerica, t...|[great, deal, alr...|[0.02826612898414...|  2.0|\n",
       "|         positive|@VirginAmerica @v...|[virginamerica, v...|[virginmedia, fly...|[-0.0038239073103...|  2.0|\n",
       "|         positive|@VirginAmerica Th...|[virginamerica, t...|            [thanks]|[-0.1997427940368...|  2.0|\n",
       "|         negative|@VirginAmerica SF...|[virginamerica, s...|[sfo, pdx, schedu...|[0.02190662324428...|  0.0|\n",
       "|         positive|@VirginAmerica So...|[virginamerica, e...|[excited, first, ...|[-0.0296566172536...|  2.0|\n",
       "|         negative|@VirginAmerica  I...|[virginamerica, f...|[flew, sfo, last,...|[0.02892880649305...|  0.0|\n",
       "|         positive|I ❤️ flying @Virg...|[flying, virginam...|            [flying]|[-0.0573806241154...|  2.0|\n",
       "|         positive|@VirginAmerica yo...|[virginamerica, y...|[know, amazingly,...|[-0.0202496654819...|  2.0|\n",
       "+-----------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
       "only showing top 20 rows"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# pipelined, very simplified\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
    "\n",
    "df2 =  df1.na.fill(\"\")\n",
    "label_stringIdx = StringIndexer(inputCol=\"airline_sentiment\", outputCol=\"label\")\n",
    "\n",
    "pipeline=Pipeline(stages = [rter, remover, word2Vec,label_stringIdx])\n",
    "\n",
    "pipelineFit = pipeline.fit(df2)\n",
    "\n",
    "df3 = pipelineFit.transform(df2)\n",
    "display(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "008c7711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train = 11041, test count= 3599\n"
     ]
    }
   ],
   "source": [
    "# training (multi-class-text-classification-with-pyspark)\n",
    "# ref: https://towardsdatascience.com/multi-class-text-classification-with-pyspark-7d78d022ed35\n",
    "\n",
    "(trainingDf, testDf) = df3.randomSplit([0.75,0.25], seed=100)\n",
    "\n",
    "print(f\"train = {trainingDf.count()}, test count= {testDf.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "619cbfde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6196671238375006"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lr classifier\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "lr = LogisticRegression(maxIter=20, regParam=0.3, elasticNetParam=0,\n",
    "                       featuresCol=\"vector\")\n",
    "lrModel=lr.fit(trainingDf)\n",
    "\n",
    "predictions = lrModel.transform(testDf)\n",
    "\n",
    "\n",
    "\n",
    "predictions.filter(predictions['prediction'] == 0) \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .limit( 10)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "80b01858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6491527920360859"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random forest\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(labelCol=\"label\", \\\n",
    "                            featuresCol=\"vector\", \\\n",
    "                            numTrees = 100)# Train model with Training Data\n",
    "rfModel = rf.fit(trainingDf)\n",
    "\n",
    "predictions = rfModel.transform(testDf)\n",
    "\n",
    "predictions.filter(predictions['prediction'] == 0) \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .limit(10)\n",
    "\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcff772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perceptron classifier\n",
    "# ref: https://spark.apache.org/docs/latest/ml-classification-regression.html#multilayer-perceptron-classifier\n",
    "\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# specify layers for the neural network:\n",
    "# input layer of size 4 (features), two intermediate of size 5 and 4\n",
    "# and output of size 3 (classes)\n",
    "#layers = [4, 5, 4, 3]\n",
    "layers = [32 ,16, 8, 4, 3]\n",
    "\n",
    "# create the trainer and set its parameters\n",
    "trainer = MultilayerPerceptronClassifier(maxIter=100, layers=layers, blockSize=128, seed=1234, featuresCol=\"vector\")\n",
    "\n",
    "# train the model\n",
    "pmodel = trainer.fit(trainingDf)\n",
    "\n",
    "# compute accuracy on the test set\n",
    "presult = pmodel.transform(testDf)\n",
    "predictionAndLabels = presult.select(\"prediction\", \"label\")\n",
    "evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "print(\"Test set accuracy = \" + str(evaluator.evaluate(predictionAndLabels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da423102",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ded0a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
